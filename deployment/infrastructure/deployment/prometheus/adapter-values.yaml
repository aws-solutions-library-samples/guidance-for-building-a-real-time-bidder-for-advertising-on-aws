affinity: {}

image:
  repository: directxman12/k8s-prometheus-adapter-arm64
  tag: v0.8.3
  pullPolicy: IfNotPresent

logLevel: 4

metricsRelistInterval: 1m

listenPort: 6443

nodeSelector:
  pool: basic-arm

priorityClassName: ""

# Url to access prometheus
prometheus:
  # Value is templated
  url: http://prom-kube-prometheus-stack-prometheus.default.svc
  port: 9090
  path: ""

replicas: 1

rbac:
  # Specifies whether RBAC resources should be created
  create: true

psp:
  # Specifies whether PSP resources should be created
  create: false

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name:

resources: {}
  # requests:
  #   cpu: 100m
  #   memory: 128Mi
  # limits:
  #   cpu: 100m
  #   memory: 128Mi

rules:
  default: false
  custom:
    # Expose average per second rate metric in last 2 minutes
    # from bidder metrics that ends with "count" or "number"

    - seriesQuery: '{namespace!="",__name__=~"^bidder_.*"}'
      seriesFilters: [ ]
      resources:
        template: <<.Resource>>
      name:
        matches: "^.*_(count|number)$"
        as: "${0}_rate"
      metricsQuery: sum(rate(<<.Series>>{<<.LabelMatchers>>}[2m])) by (<<.GroupBy>>)

  # Mounts a configMap with pre-generated rules for use. Overrides the
  # default, custom, external and resource entries
  existing:
  external: []
# - seriesQuery: '{__name__=~"^some_metric_count$"}'
#   resources:
#     template: <<.Resource>>
#   name:
#     matches: ""
#     as: "my_external_metric"
#   metricsQuery: sum(<<.Series>>{<<.LabelMatchers>>}) by (<<.GroupBy>>)
  resource:
   cpu:
     containerQuery: sum(rate(container_cpu_usage_seconds_total{<<.LabelMatchers>>}[1m])) by (<<.GroupBy>>)
     nodeQuery: sum(rate(container_cpu_usage_seconds_total{<<.LabelMatchers>>, id='/'}[1m])) by (<<.GroupBy>>)
     resources:
       overrides:
         instance:
           resource: node
         namespace:
           resource: namespace
         pod:
           resource: pod
     containerLabel: container
   memory:
     containerQuery: sum(container_memory_working_set_bytes{<<.LabelMatchers>>}) by (<<.GroupBy>>)
     nodeQuery: sum(container_memory_working_set_bytes{<<.LabelMatchers>>,id='/'}) by (<<.GroupBy>>)
     resources:
       overrides:
         instance:
           resource: node
         namespace:
           resource: namespace
         pod:
           resource: pod
     containerLabel: container
   window: 1m

service:
  annotations: {}
  port: 443
  type: ClusterIP

tls:
  enable: false
  ca: |-
    # Public CA file that signed the APIService
  key: |-
    # Private key of the APIService
  certificate: |-
    # Public key of the APIService

# Any extra arguments
extraArguments: []
  # - --tls-private-key-file=/etc/tls/tls.key
  # - --tls-cert-file=/etc/tls/tls.crt

# Any extra volumes
extraVolumes: []
  # - name: example-name
  #   hostPath:
  #     path: /path/on/host
  #     type: DirectoryOrCreate
  # - name: ssl-certs
  #   hostPath:
  #     path: /etc/ssl/certs/ca-bundle.crt
  #     type: File

# Any extra volume mounts
extraVolumeMounts: []
  #   - name: example-name
  #     mountPath: /path/in/container
  #   - name: ssl-certs
  #     mountPath: /etc/ssl/certs/ca-certificates.crt
  #     readOnly: true

tolerations: []

# Labels added to the pod
podLabels: {}

# Annotations added to the pod
podAnnotations: {}

hostNetwork:
  # Specifies if prometheus-adapter should be started in hostNetwork mode.
  #
  # You would require this enabled if you use alternate overlay networking for pods and
  # API server unable to communicate with metrics-server. As an example, this is required
  # if you use Weave network on EKS. See also dnsPolicy
  enabled: false

# When hostNetwork is enabled, you probably want to set this to ClusterFirstWithHostNet
# dnsPolicy: ClusterFirstWithHostNet

podDisruptionBudget:
  # Specifies if PodDisruptionBudget should be enabled
  # When enabled, minAvailable or maxUnavailable should also be defined.
  enabled: false
  minAvailable:
  maxUnavailable: 1
